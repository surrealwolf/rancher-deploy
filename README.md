# Rancher Cluster on Proxmox

Deploy a complete Rancher management cluster and non-production apps cluster on Proxmox using Terraform with Ubuntu 24.04 cloud images, RKE2 Kubernetes, and automated Rancher installation.

## Features

- ✅ **Full Automation**: From VMs to Rancher in a single `terraform apply`
- ✅ **Cloud Image Provisioning**: Ubuntu 24.04 LTS cloud images with automatic downloads
- ✅ **Modern Provider**: bpg/proxmox v0.90 (1.7K+ GitHub stars, 130+ contributors)
- ✅ **RKE2 Kubernetes**: Automated RKE2 installation and cluster bootstrapping
- ✅ **Rancher Deployment**: Helm-based Rancher installation with cert-manager
- ✅ **High Availability**: 3-node manager + 3-node apps clusters with HA Rancher
- ✅ **Cloud-Init Integration**: Automated networking, DNS, hostnames
- ✅ **Comprehensive Docs**: Setup guides, variable management, troubleshooting
- ✅ **Secure Configuration**: API token auth, gitignore patterns, tfvars templates

## What's Deployed

- **Rancher Manager**: 3 VMs (401-403) with RKE2 + Rancher control plane
- **Apps Cluster**: 3 VMs (404-406) with RKE2 for non-production workloads
- **Storage**: Dedicated volumes for cloud images + VM storage (local-vm-zfs)
- **Network**: Static IPs, DNS configured via cloud-init
- **Kubernetes**: RKE2 clusters automatically bootstrapped and configured
- **Rancher**: Helm-deployed with cert-manager, Ingress, and bootstrap password

## Requirements

### Local System Requirements

Your workstation/CI runner executing Terraform must have:

- **Terraform**: v1.5 or later
- **Git**: For version control and cloning this repository
- **SSH Client**: For VM authentication and access
- **curl**: For API testing and Proxmox verification
- **bash or zsh**: Shell environment (recommended for AI-assistant compatibility)
- **Internet access**: To download cloud images, RKE2, and Rancher
- **Git credentials**: Access to GitHub (public repository, no auth required)

**Optional but helpful:**
- `kubectl`: For post-deployment cluster management (can be retrieved from kubeconfig)
- `helm`: For manual Rancher customization (installed automatically during deployment)
- `jq`: For parsing JSON in scripts and debugging

### Proxmox Cluster Requirements

Your Proxmox VE cluster must have:

- **Proxmox VE 8.0+** with API token access
- **Resources**: 24 vCPU cores, 48GB RAM, 600GB storage minimum
- **Storage**: SSD/NVMe datastore (`local-vm-zfs` or similar) with qcow2 support
- **Networking**: VLAN 14 support, DHCP/static IP capability, internet access
- **DNS**: Access to 192.168.1.1 (local) or 1.1.1.1 (fallback)
- **API Token**: Required permissions listed in [API_TOKEN_AND_PERMISSIONS.md](docs/API_TOKEN_AND_PERMISSIONS.md)

### Network Requirements

**From local system:**
- Proxmox API (`https://<proxmox-ip>:8006`) and SSH
- Internet: github.com, get.rke2.io, cloud-images.ubuntu.com, docker.io, quay.io

**From Proxmox VMs:**
- Internet for RKE2 installer and container images
- Local DNS/Gateway (192.168.1.1 or equivalent)

### DNS Requirements

Rancher requires DNS records pointing to all 3 manager nodes for HA. See [DNS_CONFIGURATION.md](docs/DNS_CONFIGURATION.md) for configuration examples.

### Supported Platforms

#### Proxmox Versions
- ✅ Proxmox VE 8.x (tested, recommended)
- ✅ Proxmox VE 9.x (tested, recommended)

#### Operating Systems
- ✅ Ubuntu 24.04 LTS (default, cloud image)
- ⚠️ Other Ubuntu versions supported (change cloud image URL in terraform.tfvars)

#### RKE2 Versions
- ✅ v1.34.3+rke2r1 (tested stable, default)
- ✅ Any specific RKE2 release tag (change `rke2_version` in terraform.tfvars)
- ❌ "latest" tag (not supported - must use specific version)

#### Other
- ✅ RKE2 v1.32+
- ✅ Rancher v2.7.x and v2.8.x
- ✅ containerd runtime
- ✅ QEMU/KVM hypervisor

### Unsupported

- Single-node Proxmox, non-QEMU hypervisors, bare metal
- Cloud deployments (Azure, AWS, GCP)
- Kubernetes upgrades, multi-cluster federation, Windows VMs

## Quick Start

### 1. Create Proxmox API Token

If you haven't already created an API token, follow the guide at [docs/API_TOKEN_AND_PERMISSIONS.md](docs/API_TOKEN_AND_PERMISSIONS.md). You'll need:
- **proxmox_api_url**: Your Proxmox endpoint
- **proxmox_api_user**: Usually `root@pam`
- **proxmox_api_token_id**: Token name (e.g., `terraform`)
- **proxmox_api_token_secret**: Token secret (generated by Proxmox)

### 2. Prepare Configuration

```bash
cd /home/lee/git/rancher-deploy/terraform
cp terraform.tfvars.example terraform.tfvars
```

Edit `terraform.tfvars` with your values:
```hcl
proxmox_api_url          = "https://pve.example.com:8006/api2/json"
proxmox_api_user         = "root@pam"
proxmox_api_token_id     = "terraform-token"
proxmox_api_token_secret = "your-secret-token"
proxmox_node             = "pve"
rke2_version             = "v1.34.3+rke2r1"  # IMPORTANT: use actual version, not "latest"
rancher_hostname         = "rancher.example.com"
rancher_password         = "your-secure-password"
```

See [docs/TERRAFORM_VARIABLES.md](docs/TERRAFORM_VARIABLES.md) for all options.

### 3. Deploy Infrastructure + Kubernetes

From the root directory:

```bash
# Deploy with automatic logging (recommended)
./scripts/apply.sh

# Or manually from terraform directory
cd terraform
terraform init
terraform plan
terraform apply -auto-approve
```

**Note**: `apply.sh` enables debug logging, saves to `terraform/terraform-<timestamp>.log`, deploys everything in ~35-40 minutes.

**⚠️ Important**:
- RKE2 version must be specific release (e.g., `v1.34.3+rke2r1`), not "latest"
- Ports 9345 (server) and 6443 (API) configured automatically

### 4. Verify Deployment

```bash
# Check manager Kubernetes cluster
export KUBECONFIG=~/.kube/rancher-manager.yaml
kubectl get nodes
kubectl get pods -n kube-system

# Access Rancher
terraform output rancher_url
# Open in browser, login with:
# Username: admin
# Password: <from rancher_password in tfvars>
```

## Documentation

Core documentation for deployment and troubleshooting:

- **[docs/API_TOKEN_AND_PERMISSIONS.md](docs/API_TOKEN_AND_PERMISSIONS.md)** - Proxmox API token creation and minimum required permissions for end-to-end deployment
- **[docs/DEPLOYMENT_GUIDE.md](docs/DEPLOYMENT_GUIDE.md)** - Complete deployment walkthrough, includes kubectl tools setup
- **[docs/RANCHER_API_TOKEN_CREATION.md](docs/RANCHER_API_TOKEN_CREATION.md)** - How API tokens are created automatically, manual creation with curl
- **[docs/RANCHER_DOWNSTREAM_MANAGEMENT.md](docs/RANCHER_DOWNSTREAM_MANAGEMENT.md)** - Automatic downstream cluster registration with Rancher Manager (manifest-based)
- **[docs/DOWNSTREAM_REGISTRATION_FINDINGS.md](docs/DOWNSTREAM_REGISTRATION_FINDINGS.md)** - Technical findings on manifest-based vs. system-agent registration approach
- **[docs/DNS_CONFIGURATION.md](docs/DNS_CONFIGURATION.md)** - DNS records required for Rancher and Kubernetes API access
- **[docs/CLOUD_IMAGE_SETUP.md](docs/CLOUD_IMAGE_SETUP.md)** - Cloud image provisioning and VM configuration
- **[docs/MODULES_AND_AUTOMATION.md](docs/MODULES_AND_AUTOMATION.md)** - Terraform modules, variables, and automation details
- **[docs/TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md)** - Common issues and solutions

## Project Structure

```
.
├── scripts/                      # Helper scripts
│   ├── apply.sh                  # Deploy with automatic logging
│   ├── destroy.sh                # Destroy infrastructure
│   ├── create-rancher-api-token.sh # Create API token manually
│   └── test-rancher-api-token.sh # Test API connectivity
├── README.md                     # This file
├── CHANGELOG.md                  # Version history
├── CODE_OF_CONDUCT.md            # Community guidelines
├── CONTRIBUTING.md               # Development guidelines
├── docs/                         # Core documentation
│   ├── DEPLOYMENT_GUIDE.md       # Complete deployment walkthrough
│   ├── RANCHER_API_TOKEN_CREATION.md # API token creation
│   ├── RANCHER_DOWNSTREAM_MANAGEMENT.md # Downstream registration
│   ├── DNS_CONFIGURATION.md      # DNS setup
│   ├── CLOUD_IMAGE_SETUP.md      # Cloud image provisioning
│   ├── MODULES_AND_AUTOMATION.md # Terraform modules
│   └── TROUBLESHOOTING.md        # Issue resolution
└── terraform/                    # Terraform configuration
    ├── main.tf                   # Cluster definitions
    ├── provider.tf               # Provider configuration
    ├── variables.tf              # Variables
    ├── outputs.tf                # Outputs
    ├── terraform.tfvars.example  # Config template
    ├── fetch-token.sh            # RKE2 token helper
    └── modules/
        ├── proxmox_vm/           # VM creation module
        ├── rke2_manager_cluster/ # Manager verification
        └── rke2_downstream_cluster/ # Apps verification
```

## Key Features

### Reliable VM Creation

The deployment uses the **bpg/proxmox Terraform provider** (v0.90) with:
- ✅ Exponential backoff retry logic for API calls
- ✅ Proper task completion verification
- ✅ Comprehensive error handling
- ✅ Full Proxmox VE 8.x and 9.x support

### Automated Configuration

Each VM is automatically configured with:
- Cloud-init for OS customization
- Network settings (VLAN 14, static IP, DNS)

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for development setup and code standards. See [CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md) for community standards.

## Changelog

See [CHANGELOG.md](CHANGELOG.md) for version history, features, and major changes.

## License

This project is licensed under the MIT License.

---

**Built with Claude Haiku 4.5** - This project was developed using Claude Haiku 4.5, an AI assistant optimized for code generation and infrastructure automation.
